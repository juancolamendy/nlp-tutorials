{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4a0b85-c41c-4272-9a4e-ed8b585e9b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import load_dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fc10f60-daad-4ae4-9fbe-84472bd52f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in /Users/jcolamendy/python/tutorials/nlp-tutorials/venv/lib/python3.9/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/jcolamendy/python/tutorials/nlp-tutorials/venv/lib/python3.9/site-packages (from faiss-cpu) (23.2)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp39-cp39-macosx_11_0_arm64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a60a09-043c-48aa-a0f8-38d8c46377d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQUATION: x^3 + 7 = 12\n",
      "\n",
      "SOLUTION: \n",
      "Subtract 7 from both sides:\n",
      "x^3 = 5\n",
      "\n",
      "Take the cube root of both sides:\n",
      "x = ∛5\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Write out the following equation using algebraic symbols then solve it. Use the format\\n\\nEQUATION:...\\nSOLUTION:...\\n\\n\",\n",
    "        ),\n",
    "        (\"human\", \"{equation_statement}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "chain_input = {\"equation_statement\": RunnablePassthrough()}\n",
    "runnable = (\n",
    "    chain_input | prompt | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2002f93-a32d-4c78-9cd6-5ac713317d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain_input = {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "retrieval_chain = (\n",
    "    chain_input\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a39e41a-eb55-43eb-933b-21930ab32bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain_input = RunnablePassthrough.assign(\n",
    "    **{\n",
    "        \"context\": itemgetter('question') | retriever, \n",
    "        \"question\": itemgetter('question'),\n",
    "    }\n",
    ")\n",
    "retrieval_chain = (\n",
    "    chain_input\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb150870-02cf-44f1-9b85-3da60be53ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain_input = RunnablePassthrough.assign(\n",
    "    context = itemgetter('question') | retriever).assign(\n",
    "    question = itemgetter('question')\n",
    ")\n",
    "retrieval_chain = (\n",
    "    chain_input\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec892204-e3bb-425a-9f88-b1a699ede7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': []}\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "system_template = \"\"\"You are a helpful chatbot. \n",
    "\n",
    "Your task is to answer questions given a context and a chat history.\n",
    "\n",
    "Follow the instructions below.\n",
    "% INSTRUCTIONS:\n",
    "- only answer the questions using the context or chat history below\n",
    "- if you don't know the answer, just answer: 'I don't know'\n",
    "\n",
    "% CONTEXT:\n",
    "{context}\n",
    "\n",
    "% CHAT HISTORY:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"\\n% QUESTION:\\n{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, chat_memory=chat_history)\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "# {'history': [HumanMessage(content='hi im bob'), AIMessage(content='Hello Bob! How can I assist you today?')]}\n",
    "\n",
    "chain_input =  RunnablePassthrough.assign(\n",
    "    history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")).assign(\n",
    "    context = itemgetter('input') | retriever\n",
    ")\n",
    "chain =  chain_input | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e04d2eb-edd6-4552-8065-c1bbfdd7766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:load_memory_variables] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:load_memory_variables] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"history\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"history\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"history\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history>] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\",\n",
      "  \"history\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\",\n",
      "  \"history\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\",\n",
      "  \"history\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\",\n",
      "  \"history\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\",\n",
      "  \"history\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"what is my name\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] [224ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] [228ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context>] [229ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful chatbot. \\n\\nYour task is to answer questions given a context and a chat history.\\n\\nFollow the instructions below.\\n% INSTRUCTIONS:\\n- only answer the questions using the context or chat history below\\n- if you don't know the answer, just answer: 'I don't know'\\n\\n% CONTEXT:\\n[Document(page_content='harrison worked at kensho')]\\n\\n% CHAT HISTORY:\\n\\nHuman: \\n% QUESTION:\\nwhat is my name\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [584ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I don't know\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I don't know\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 4,\n",
      "                \"prompt_tokens\": 103,\n",
      "                \"total_tokens\": 107\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5060c76e-e756-4c4d-aa41-55c1208f153a-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 4,\n",
      "      \"prompt_tokens\": 103,\n",
      "      \"total_tokens\": 107\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [830ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "content=\"I don't know\" response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 103, 'total_tokens': 107}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-5060c76e-e756-4c4d-aa41-55c1208f153a-0'\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"what is my name\"}\n",
    "response = chain.invoke(inputs, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ca6ad39-bd04-4b88-9fc8-77652c246fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='hi im harison'), AIMessage(content='Hello harison! How can I assist you today?')]}\n"
     ]
    }
   ],
   "source": [
    "chat_history.add_user_message(\"hi im harison\")\n",
    "chat_history.add_ai_message('Hello harison! How can I assist you today?')\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b07520ad-1a75-462d-b4b1-f9892dda0e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:load_memory_variables] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is my name\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:load_memory_variables] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history>] [7ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"what is my name\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] [374ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] [376ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context>] [377ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful chatbot. \\n\\nYour task is to answer questions given a context and a chat history.\\n\\nFollow the instructions below.\\n% INSTRUCTIONS:\\n- only answer the questions using the context or chat history below\\n- if you don't know the answer, just answer: 'I don't know'\\n\\n% CONTEXT:\\n[Document(page_content='harrison worked at kensho')]\\n\\n% CHAT HISTORY:\\n\\nHuman: hi im harison\\nAI: Hello harison! How can I assist you today?\\nHuman: \\n% QUESTION:\\nwhat is my name\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [711ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Your name is harison.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Your name is harison.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 126,\n",
      "                \"total_tokens\": 132\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f0e76e8a-cbce-4135-af1c-809dd109c266-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 126,\n",
      "      \"total_tokens\": 132\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.11s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "content='Your name is harison.' response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 126, 'total_tokens': 132}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-f0e76e8a-cbce-4135-af1c-809dd109c266-0'\n"
     ]
    }
   ],
   "source": [
    "# questions\n",
    "inputs = {\"input\": \"what is my name\"}\n",
    "response = chain.invoke(inputs, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07d5d9a6-80e6-4c47-8273-edc530200c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"where harrison work\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"where harrison work\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"where harrison work\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"where harrison work\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:load_memory_variables] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"where harrison work\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:load_memory_variables] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history>] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"where harrison work\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] [197ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] [199ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context>] [200ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful chatbot. \\n\\nYour task is to answer questions given a context and a chat history.\\n\\nFollow the instructions below.\\n% INSTRUCTIONS:\\n- only answer the questions using the context or chat history below\\n- if you don't know the answer, just answer: 'I don't know'\\n\\n% CONTEXT:\\n[Document(page_content='harrison worked at kensho')]\\n\\n% CHAT HISTORY:\\n\\nHuman: hi im harison\\nAI: Hello harison! How can I assist you today?\\nHuman: \\n% QUESTION:\\nwhere harrison work\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [804ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Harrison worked at Kensho.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Harrison worked at Kensho.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 126,\n",
      "                \"total_tokens\": 133\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c437635b-20ab-4e4b-ade0-57d019ba87c3-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 7,\n",
      "      \"prompt_tokens\": 126,\n",
      "      \"total_tokens\": 133\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.02s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "content='Harrison worked at Kensho.' response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 126, 'total_tokens': 133}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-c437635b-20ab-4e4b-ade0-57d019ba87c3-0'\n"
     ]
    }
   ],
   "source": [
    "# questions\n",
    "inputs = {\"input\": \"where harrison work\"}\n",
    "response = chain.invoke(inputs, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9e98df6-db9d-44f7-9a8c-d0098f02b294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='hi im harison'), AIMessage(content='Hello harison! How can I assist you today?'), HumanMessage(content='what is langchain'), AIMessage(content='LangChain is an open-source framework that helps developers build applications using large language models (LLMs)')]}\n"
     ]
    }
   ],
   "source": [
    "chat_history.add_user_message(\"what is langchain\")\n",
    "chat_history.add_ai_message('LangChain is an open-source framework that helps developers build applications using large language models (LLMs)')\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ffa3733-237f-42f5-8d02-703cbdaf98f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Is langchain open-source or closed-source?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Is langchain open-source or closed-source?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Is langchain open-source or closed-source?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Is langchain open-source or closed-source?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:load_memory_variables] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Is langchain open-source or closed-source?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:load_memory_variables] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history>] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Is langchain open-source or closed-source?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] [257ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] [260ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context>] [262ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [2ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful chatbot. \\n\\nYour task is to answer questions given a context and a chat history.\\n\\nFollow the instructions below.\\n% INSTRUCTIONS:\\n- only answer the questions using the context or chat history below\\n- if you don't know the answer, just answer: 'I don't know'\\n\\n% CONTEXT:\\n[Document(page_content='harrison worked at kensho')]\\n\\n% CHAT HISTORY:\\n\\nHuman: hi im harison\\nAI: Hello harison! How can I assist you today?\\nHuman: what is langchain\\nAI: LangChain is an open-source framework that helps developers build applications using large language models (LLMs)\\nHuman: \\n% QUESTION:\\nIs langchain open-source or closed-source?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [495ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"LangChain is open-source.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"LangChain is open-source.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 6,\n",
      "                \"prompt_tokens\": 163,\n",
      "                \"total_tokens\": 169\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ebee9f80-b937-4d58-9f47-449543677f05-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 163,\n",
      "      \"total_tokens\": 169\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [774ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "content='LangChain is open-source.' response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 163, 'total_tokens': 169}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-ebee9f80-b937-4d58-9f47-449543677f05-0'\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"Is langchain open-source or closed-source?\"}\n",
    "response = chain.invoke(inputs, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6194445d-edc6-4f9b-b9aa-26f06412a9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='hi im harison'), AIMessage(content='Hello harison! How can I assist you today?'), HumanMessage(content='what is langchain'), AIMessage(content='LangChain is an open-source framework that helps developers build applications using large language models (LLMs)'), HumanMessage(content='what is linux'), AIMessage(content=\"Linux is an open-source operating system (OS) that manages a computer's hardware and resources, like its CPU, memory.\")]}\n"
     ]
    }
   ],
   "source": [
    "chat_history.add_user_message(\"what is linux\")\n",
    "chat_history.add_ai_message(\"Linux is an open-source operating system (OS) that manages a computer's hardware and resources, like its CPU, memory.\")\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de2abda2-dbe9-4062-881b-0bdf7b89896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Linux?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Linux?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Linux?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Linux?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:load_memory_variables] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Linux?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:load_memory_variables] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history> > chain:RunnableParallel<history>] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<history>] [8ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is Linux?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context> > chain:RunnableSequence] [247ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context> > chain:RunnableParallel<context>] [249ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableAssign<context>] [251ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful chatbot. \\n\\nYour task is to answer questions given a context and a chat history.\\n\\nFollow the instructions below.\\n% INSTRUCTIONS:\\n- only answer the questions using the context or chat history below\\n- if you don't know the answer, just answer: 'I don't know'\\n\\n% CONTEXT:\\n[Document(page_content='harrison worked at kensho')]\\n\\n% CHAT HISTORY:\\n\\nHuman: hi im harison\\nAI: Hello harison! How can I assist you today?\\nHuman: what is langchain\\nAI: LangChain is an open-source framework that helps developers build applications using large language models (LLMs)\\nHuman: what is linux\\nAI: Linux is an open-source operating system (OS) that manages a computer's hardware and resources, like its CPU, memory.\\nHuman: \\n% QUESTION:\\nWhat is Linux?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [941ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Linux is an open-source operating system (OS) that manages a computer's hardware and resources, like its CPU, memory.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Linux is an open-source operating system (OS) that manages a computer's hardware and resources, like its CPU, memory.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 25,\n",
      "                \"prompt_tokens\": 194,\n",
      "                \"total_tokens\": 219\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-9b953e63-91ef-4f24-9e87-773d6ccdf660-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 25,\n",
      "      \"prompt_tokens\": 194,\n",
      "      \"total_tokens\": 219\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.21s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "content=\"Linux is an open-source operating system (OS) that manages a computer's hardware and resources, like its CPU, memory.\" response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 194, 'total_tokens': 219}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-9b953e63-91ef-4f24-9e87-773d6ccdf660-0'\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"What is Linux?\"}\n",
    "response = chain.invoke(inputs, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
