{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d414eef-394a-46a8-97a8-93aa5ed57f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import load_dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6c06d658-bd83-4c63-85c1-b0d04e05490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0395952-c30e-498d-bb17-454c19e05b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful chatbot capable of performing a variety of tasks on the data available\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef0dcaf4-f0a4-4da1-adcf-14a995ed046a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chat_history', 'input']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fab36274-e4c5-4771-bc4e-b2b9020431ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8942c905-e6e4-4878-9720-105a848e99fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': []}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98f96b7c-37b2-4528-b442-aa422e78960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hi, my name is John\"},  # user message\n",
    "    {\"output\": \"Hey John, what's up? I'm an AI model called J.\"}  # AI response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec2ea2ae-c360-43d3-9db1-e37a1b63626e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [HumanMessage(content='Hi, my name is John', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hey John, what's up? I'm an AI model called J.\", additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6128016c-afa5-4067-a1a8-0ec918412dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"I'm researching the different types of conversational memory.\"},  # user message\n",
    "    {\"output\": \"That's interesting, what are some examples?\"}  # AI response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bc00113-bf03-4601-97d0-95469c558d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [HumanMessage(content='Hi, my name is John', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hey John, what's up? I'm an AI model called J.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc626fc6-9c99-48e9-aa25-837447e25473",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92c49086-d60a-4327-b86a-9e33189e51bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': []}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "940d5e8a-502e-41fa-bb85-2d1cece10a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain_input = RunnablePassthrough.assign(\n",
    "#     **{\n",
    "#         'chat_history': RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\")\n",
    "#     }\n",
    "# )\n",
    "# closure around the memory\n",
    "def get_prompt_input(inputs):\n",
    "    chat_history = (RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\")).invoke({})\n",
    "    return {\"input\": inputs[\"input\"], \"chat_history\": chat_history}\n",
    "\n",
    "chain_input = RunnableLambda(get_prompt_input)\n",
    "# chain_input = {\n",
    "#     \"input\": lambda x: x[\"input\"],\n",
    "#     \"chat_history\": lambda _: (RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\")).invoke({})\n",
    "# }\n",
    "# prompt has input variables: chat_history, input\n",
    "chain = chain_input | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "10e7c1f7-7271-4008-852f-6f3086b30a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='Hello Juan! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 31, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BES14PDH8Jmh1y6e1RXT7Mjhshjio', 'finish_reason': 'stop', 'logprobs': None} id='run-8c32eee9-3908-472e-ad70-915522537e48-0' usage_metadata={'input_tokens': 31, 'output_tokens': 11, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "input = 'Hi Im Juan'\n",
    "inputs = {\"input\": input}\n",
    "response = chain.invoke(inputs)\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "052a286d-dcb6-4fba-9ad4-952092fef064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.memory.buffer.ConversationBufferMemory'>\n",
      "<class 'langchain_core.chat_history.InMemoryChatMessageHistory'>\n",
      "{'chat_history': []}\n"
     ]
    }
   ],
   "source": [
    "print(type(memory))\n",
    "print(type(memory.chat_memory))\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c86d31f1-ee5d-4a17-a333-2c0253535114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [HumanMessage(content='Hi Im Juan', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello Juan! How can I assist you today?', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "memory.chat_memory.add_user_message(input)\n",
    "memory.chat_memory.add_ai_message(response.content)\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3bdf1e5f-f50f-41b9-8124-cece223ed3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your name is Juan. How can I help you, Juan?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 53, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BES1t5EozO1ZHf5MnChpPTkgCybX0', 'finish_reason': 'stop', 'logprobs': None} id='run-af08d158-9923-4f7d-9778-c1b63de5aa4a-0' usage_metadata={'input_tokens': 53, 'output_tokens': 14, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "input = 'what is my name'\n",
    "inputs = {\"input\": input}\n",
    "response = chain.invoke(inputs)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ef7b69fc-fa20-4d31-a1ff-84dc73731955",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "67a79026-becc-4d6f-82bf-301b5a316b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "chat_map = {}\n",
    "def get_chat_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0f5a1490-bec1-490b-b30e-6fc33580b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d421c0e1-fa9c-4e6c-bd94-9bbab4c3fe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Juan! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 34, 'total_tokens': 45, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BESGbTPvh70o4vqri7O5bIsECfbmv', 'finish_reason': 'stop', 'logprobs': None}, id='run-728ff3d8-9bbf-4aa1-bd2e-ac932b0a8398-0', usage_metadata={'input_tokens': 34, 'output_tokens': 11, 'total_tokens': 45, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"input\": \"Hi, my name is Juan\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "55a6ea8e-3248-4242-96e8-2fe98b35c2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Juan. How can I help you, Juan?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 58, 'total_tokens': 72, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BESHFlachkdGbJeuhhxSLBnSZmxDq', 'finish_reason': 'stop', 'logprobs': None}, id='run-785ec81d-b8cb-40ac-9f9c-129dd2eda0b1-0', usage_metadata={'input_tokens': 58, 'output_tokens': 14, 'total_tokens': 72, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"input\": \"What is my name again?\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ee812587-da44-4fb6-8c29-d17b4ede2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class BufferWindowMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "    k: int = Field(default_factory=int)\n",
    "\n",
    "    def __init__(self, k: int):\n",
    "        super().__init__(k=k)\n",
    "        print(f\"Initializing BufferWindowMessageHistory with k={k}\")\n",
    "\n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        \"\"\"Add messages to the history, removing any messages beyond\n",
    "        the last `k` messages.\n",
    "        \"\"\"\n",
    "        self.messages.extend(messages)\n",
    "        self.messages = self.messages[-self.k:]\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear the history.\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3ca128ce-9557-4dd4-a17c-b741258e3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_map = {}\n",
    "def get_chat_history(session_id: str, k: int = 4) -> BufferWindowMessageHistory:\n",
    "    print(f\"get_chat_history called with session_id={session_id} and k={k}\")\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = BufferWindowMessageHistory(k=k)\n",
    "    # remove anything beyond the last\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "239d62b6-b87a-46b8-a6d4-a84df2319ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2e7bb8fa-deed-467a-8ebd-cc46e6ea1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"The session ID to use for the chat history\",\n",
    "            default=\"id_default\",\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"k\",\n",
    "            annotation=int,\n",
    "            name=\"k\",\n",
    "            description=\"The number of messages to keep in the history\",\n",
    "            default=4,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "797494fa-0c86-4732-ba52-4612bb9e37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_chat_history called with session_id=id_k4 and k=4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Juan! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 34, 'total_tokens': 45, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BEeU0gefil3M0KKrLtUBXo8GPTWbb', 'finish_reason': 'stop', 'logprobs': None}, id='run-15737a81-7c34-4d1d-81a2-29f45a8f4a45-0', usage_metadata={'input_tokens': 34, 'output_tokens': 11, 'total_tokens': 45, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"input\": \"Hi, my name is Juan\"},\n",
    "    config={\"configurable\": {\"session_id\": \"id_k4\", \"k\": 4}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f4282259-9a3d-455b-ae22-ce3dd91c6008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, my name is Juan', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello Juan! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 34, 'total_tokens': 45, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BEeU0gefil3M0KKrLtUBXo8GPTWbb', 'finish_reason': 'stop', 'logprobs': None}, id='run-15737a81-7c34-4d1d-81a2-29f45a8f4a45-0', usage_metadata={'input_tokens': 34, 'output_tokens': 11, 'total_tokens': 45, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_k4\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9c4e7807-caab-4407-b098-cb261b0fbfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_chat_history called with session_id=id_k4 and k=4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Juan.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 58, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BEeWOZpIYVnuxA4jr0U3nbv7GtElD', 'finish_reason': 'stop', 'logprobs': None}, id='run-e202d3b1-5d2d-4b05-910f-1429a112f7bc-0', usage_metadata={'input_tokens': 58, 'output_tokens': 6, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"input\": \"what is my name again?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"id_k4\", \"k\": 4}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "327d17fb-161e-4016-a791-cd004ebf2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "\n",
    "class ConversationSummaryMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "    llm: ChatOpenAI = Field(default_factory=ChatOpenAI)\n",
    "\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        super().__init__(llm=llm)\n",
    "\n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        \"\"\"Add messages to the history and summarize them.\"\"\"\n",
    "        self.messages.extend(messages)\n",
    "        \n",
    "        # Get existing summary or use an empty string if no messages exist\n",
    "        existing_summary = \"\"\n",
    "        if self.messages and len(self.messages) > 0:\n",
    "            existing_summary = \"\\n\".join([msg.content for msg in self.messages])\n",
    "        \n",
    "        # construct the summary chat messages\n",
    "        summary_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"Given the existing conversation summary and the new messages, \"\n",
    "                \"generate a new summary of the conversation. Ensuring to maintain \"\n",
    "                \"as much relevant information as possible.\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"Existing conversation summary:\\n{existing_summary}\\n\\n\"\n",
    "                \"New messages:\\n{messages}\"\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # format the messages and invoke the LLM\n",
    "        new_summary = self.llm.invoke(\n",
    "            summary_prompt.format_messages(\n",
    "                existing_summary=existing_summary,\n",
    "                messages=[x.content for x in messages]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # replace the existing history with a single system summary message\n",
    "        self.messages = [SystemMessage(content=new_summary.content)]\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear the history.\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dd470b78-6d3d-4015-a613-640191765660",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_map = {}\n",
    "def get_chat_history(session_id: str, llm: ChatOpenAI) -> ConversationSummaryMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = ConversationSummaryMessageHistory(llm=llm)\n",
    "    # return the chat history\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3bffea24-6bb5-4a05-88ad-08bc3d1fdd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"The session ID to use for the chat history\",\n",
    "            default=\"id_default\",\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"llm\",\n",
    "            annotation=ChatOpenAI,\n",
    "            name=\"LLM\",\n",
    "            description=\"The LLM to use for the conversation summary\",\n",
    "            default=model,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d02cb6ac-ac61-4f27-85fd-6ebcd2ac4beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Juan! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 34, 'total_tokens': 45, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BEf0z6f76bXWyy6FBUfASjJpEOIog', 'finish_reason': 'stop', 'logprobs': None}, id='run-00fa157b-987e-49cb-bbb8-6e6b1ea92389-0', usage_metadata={'input_tokens': 34, 'output_tokens': 11, 'total_tokens': 45, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"input\": \"Hi, my name is Juan\"},\n",
    "    config={\"session_id\": \"id_123\", \"llm\": model}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "951c1f0d-089d-409e-8fe7-80b61c8a44f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Juan introduced himself and welcomed the assistance offered by the other person in the conversation.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f05d0715-9adf-408e-9930-bfd59abbbdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's an interesting topic! Conversational memory can refer to different aspects of memory related to conversations. Some common types of conversational memory include working memory (the temporary storage and manipulation of information during a conversation), episodic memory (memory for specific events or episodes in a conversation), and semantic memory (general knowledge about language and conversation). \\n\\nIf you have any specific questions or if you need more information on a particular aspect of conversational memory, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 59, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BEf3r9rVyw1lDgzGhYi9BGo698Z3O', 'finish_reason': 'stop', 'logprobs': None}, id='run-2dd3e740-9032-4c27-91a2-948d4fc651b8-0', usage_metadata={'input_tokens': 59, 'output_tokens': 95, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"input\": \"I'm researching the different types of conversational memory.\"},\n",
    "    config={\"session_id\": \"id_123\", \"llm\": model}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5f5970aa-1ae9-4d6e-bb1b-1b387de66ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Juan and the other person in the conversation discussed the topic of conversational memory, touching on different aspects such as working memory, episodic memory, and semantic memory. The conversation invited questions about specific aspects of conversational memory for further discussion and exploration.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2b1958f7-75bf-412c-9b21-6804af6382e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='An AI (Artificial Intelligence) agent is a software program or system that is designed to act intelligently to achieve a certain goal or perform specific tasks. AI agents are capable of perceiving their environment, making decisions, and taking actions to achieve their objectives. These agents can operate autonomously, adapt to changing conditions, and learn from experience to improve their performance over time.\\n\\nThere are various types of AI agents, each with specific characteristics and capabilities:\\n\\n1. **Simple Reflex Agents**: These agents make decisions based only on the current percept (input) without considering past perceptions or future consequences. They operate using a simple \"if-then\" rule-based system.\\n\\n2. **Model-Based Reflex Agents**: These agents maintain an internal state representing their model of the world, allowing them to make decisions based on both the current percept and the internal world model.\\n\\n3. **Goal-Based Agents**: These agents are designed to achieve specific goals by selecting actions that will lead to the desired outcomes. They consider the current state, the goal to be achieved, and possible actions to reach that goal.\\n\\n4. **Utility-Based Agents**: In addition to goals, these agents consider the utility or value associated with different outcomes when making decisions. They aim to maximize the expected utility of their actions.\\n\\n5. **Learning Agents**: These agents have the ability to learn from the environment and improve their performance over time. They use various learning algorithms, such as reinforcement learning or supervised learning, to adapt their behavior based on feedback.\\n\\n6. **Logical Agents**: These agents use logical reasoning and inference to make decisions. They manipulate symbolic representations of knowledge to derive conclusions and choose actions.\\n\\n7. **Software Agents**: These are autonomous software programs that can perform tasks on behalf of users or other systems. They can interact with other agents, services, or users to accomplish their goals.\\n\\nAI agents are used in various applications, such as autonomous vehicles, recommendation systems, natural language processing, and robotics. They play a crucial role in enabling automation and intelligent decision-making in diverse domains.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 408, 'prompt_tokens': 91, 'total_tokens': 499, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BEf5IWoxQpK68u1GdWTpJCsY1FgNl', 'finish_reason': 'stop', 'logprobs': None}, id='run-d54c7bf9-94ae-4c5a-bd8c-89eed17bf005-0', usage_metadata={'input_tokens': 91, 'output_tokens': 408, 'total_tokens': 499, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"input\": \"Explain in details what is an AI agent\"},\n",
    "    config={\"session_id\": \"id_123\", \"llm\": model}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4b145a31-b8c0-47ca-992b-70e73d3c6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='The conversation delved into the detailed explanation of what an AI agent is, describing it as a software program or system designed to act intelligently to achieve goals. Various types of AI agents were discussed, including simple reflex agents, model-based reflex agents, goal-based agents, utility-based agents, learning agents, logical agents, and software agents. Each type possesses unique characteristics and capabilities in perceiving environments, decision-making, and achieving objectives. The utilization of AI agents in applications like autonomous vehicles, recommendation systems, natural language processing, and robotics was highlighted as enabling automation and intelligent decision-making across diverse domains.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_123\"].messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
